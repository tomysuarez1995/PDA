{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b028086",
   "metadata": {},
   "source": [
    "# <center> <span style='color:#3c3b5f'>Introducción a Pandas</span></center>\n",
    "\n",
    "Módulo 7 - Parte teórica\n",
    "\n",
    "**Profesor Adjunto:** Mag. Bioing. Baldezzari Lucas\n",
    "\n",
    "<p style='text-align: left;'> V2022 </p>\n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6990b8",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Instalando Pandas</span>\n",
    "\n",
    "La forma rápida y sencilla es usando *pip* desde consola.\n",
    "\n",
    "```Python\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "Recordar antes activar el ambiente de trabajo mediante *conda actívate miEnv*, de esta manera numpy se instalará en el ambiente de trabajo.\n",
    "\n",
    "Si ya tenemos numpy instalado podemos ver su versión ejecutando,\n",
    "\n",
    "```Python\n",
    "import pandas\n",
    "pandas.__version__\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d9ce15",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>¿Qué es Pandas?</span>\n",
    "\n",
    "Es una librería de código abierto para el análisis de datos. Utiliza Numpy para administrar y manipular datos. Por otro lado, utiliza algunas funcionalidades básicas de Matplotlib para graficar.\n",
    "\n",
    "Con Pandas introducimos dos tipos de datos nuevos,\n",
    "\n",
    "- [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html): Representa nuestra tabla de datos o spreadshet.\n",
    "- [Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html): Que representa una columna dentro de mi DataFrame. Los *pandas.series* contienen información **indexada**. Esta indexación puede ser por número o bien podría tener un nombre.\n",
    "\n",
    "[Sitio oficial](https://pandas.pydata.org/docs/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b469c",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Primeros pasos: Cargando archivos en DataFrames</span>\n",
    "\n",
    "Pandas posee varios métodos de Entrada/Salida (Input/Ouput, IO) para leer y escribir archivos de diferentes formatos. Algunos de los formatos disponibles, según la [documentación oficial](https://pandas.pydata.org/docs/user_guide/io.html), son,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc78d81",
   "metadata": {},
   "source": [
    "<img src=\"figs/io.png\" style=\" width:520px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0d825",
   "metadata": {},
   "source": [
    "En este curso trabajaremos mayoritariamente con archivos de texto y csv, por lo tanto, utilizaremos el método, [*pandas.read_csv()*](https://pandas.pydata.org/docs/user_guide/io.html#io-read-csv-table).\n",
    "\n",
    "El constructor del método mencionado recibe una gran cantidad de parámetros, como podemos ver debajo. No obstante, en este curso sólo utilizaremos los básicos.\n",
    "\n",
    "```python\n",
    "pandas.read_csv(filepath_or_buffer, sep=NoDefault.no_default, delimiter=None, header='infer', names=NoDefault.no_default, index_col=None, usecols=None, squeeze=None, prefix=NoDefault.no_default, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=None, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, error_bad_lines=None, warn_bad_lines=None, on_bad_lines=None, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None, storage_options=None)\n",
    "```\n",
    "\n",
    "Si el archivo pudo ser abierto, el método *pandas.read_csv()* nos devuelve un *DataFrame*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312a6a9",
   "metadata": {},
   "source": [
    "A continuación trabajaremos con el set de datos de Eficiencia energética visto en la ejercitación del módulo de Numpy.\n",
    "\n",
    "Cargamos el archivo en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a019f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datos = pd.read_csv(\"datasets/eficienciaEnergética.csv\")\n",
    "print(type(datos)) ## vemos que el tipo de datos es 'pandas.core.frame.DataFrame'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa695e7",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Conociendo un poco más sobre los *DataFrame*</span></center>\n",
    "\n",
    "Vimos como abrir un archivo csv y formar un data frame. Ahora bien, vamos a analizar qué datos tenemos dentro del dataframe cargado, para esto utilizaremos algunos métodos propios de los objetos *DataFrame*, a saber:\n",
    "\n",
    "- *DataFrame.head()*: Retorna las primeras filas del dataframe.\n",
    "- *DataFrame.info()*: Muestra información de cada columna, como ser el tipo de datos y la cantidad de valores *perdidos* (los cuales pandas no pudo cargar).\n",
    "- *DataFrame.shape*: Retorna el número de filas y columnas. No confundir con el *shape* de Numpy.\n",
    "- *DataFrame.describe()*: Retorna un resúmen de algunos valores estadísticos de aquellas columnas que contienen datos numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cbb08e",
   "metadata": {},
   "source": [
    "##### [DataFrame.head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)\n",
    "\n",
    "El método esta definido cómo,\n",
    "\n",
    "```Python\n",
    "DataFrame.head(n=5)\n",
    "```\n",
    "\n",
    "La documentación oficial dice:\n",
    "\n",
    "> This function returns the first n rows for the object based on position. It is useful for quickly testing if your object has the right type of data in it.\n",
    "\n",
    "Veamos esto con los datos que hemos cargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c896b4",
   "metadata": {},
   "source": [
    "##### [DataFrame.info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)\n",
    "\n",
    "El método esta definido cómo,\n",
    "\n",
    "```Python\n",
    "DataFrame.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None, null_counts=None)\n",
    "```\n",
    "\n",
    "La documentación oficial nos dice,\n",
    "\n",
    "> This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e0010",
   "metadata": {},
   "source": [
    "A partir del método *.info()* podemos ver que el rango de datos va de 0 a 767, dándonos 768 filas. Al mismo tiempo nos dice que tenemos un total de 10 columnas, numeradas del 0 a 9. Además nos informa del nombre asociada a cada columna, por ejemplo, *Relative_Compactness* la cual posee 768 datos *non-null* con valores del tipo *float64*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7548cb",
   "metadata": {},
   "source": [
    "##### DataFrame.shape\n",
    "\n",
    "Este es un **atributo** y no un método (observar que no tiene paréntesis). *DataFrame.shape* nos retorna el número de filas y columnas que posee.\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21545c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b48f38",
   "metadata": {},
   "source": [
    "##### [DataFrame.describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)\n",
    "\n",
    "El método esta definido cómo,\n",
    "\n",
    "```Python\n",
    "DataFrame.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)\n",
    "```\n",
    "\n",
    "La documentación oficial nos dice,\n",
    "\n",
    "> Generate descriptive statistics.\n",
    "\n",
    "> Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values.\n",
    "\n",
    "> Analyzes both numeric and object series, as well as DataFrame column sets of mixed data types. The output will vary depending on what is provided. Refer to the notes below for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d389d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe(percentiles=[0.1,0.5,0.9])\n",
    "\n",
    "## Sin la columna Orientation\n",
    "# datos.drop(columns = \"Orientation\").describe(percentiles=[0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ec618",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Valores, columnas e índices de un DataFrame</span></center>\n",
    "\n",
    "Hay tres atributos importantes dentro de un DataFrame que son de utilidad, estos son,\n",
    "\n",
    "DataFrame.values: Array 2D con los valores que componen el DataFrame.\n",
    "DataFrame.columns: Una lista con los nombres de las columnas.\n",
    "DataFrame.index: Índices numéricos para cada fila. O podrían ser con nombres.\n",
    "\n",
    "Veamos esto en acción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .values\n",
    "print(type(datos.values)) ##array de numpy\n",
    "print(datos.values)\n",
    "print()\n",
    "print(datos.values.shape)\n",
    "\n",
    "## Podríamos indexar el array de .values como hemos visto en el módulo de numpy\n",
    "print(datos.values[1,:]) ## segunda fila de mi dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ¿Cuales son las columnas del dataframe?\n",
    "print(datos.columns)\n",
    "print(datos.columns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ¿Qué podemos decir acerca de los índices de nuestro dataframe?\n",
    "datos.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea338cf",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Utilizando *DataFrame.loc[]* para obtener datos de un renglón</span></center>\n",
    "\n",
    "Podemos usar [*DataFrame.loc[]*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) para acceder a un renglón en particular de mi set de datos, aprovechando que Pandas utiliza *indexación* para acceder a los datos, ya sea por un valor numérico o bien por nombre.\n",
    "\n",
    "Veamos esto con un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
    "     index=['cobra', 'viper', 'sidewinder'],\n",
    "     columns=['max_speed', 'shield'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94457b6d",
   "metadata": {},
   "source": [
    "En el ejemplo anterior vemos que tenemos tres renglones con tres nombres, podríamos acceder al renglón utilizando el nombre del mismo.\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6eca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[\"viper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f878b8",
   "metadata": {},
   "source": [
    "**Nota:** Veremos más adelante otras formas de usar .loc[]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63f618",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Obteniendo subsets</span>\n",
    "\n",
    "Con Pandas es posible obtener subsets a partir de otro set de datos.\n",
    "\n",
    "Podríamos utilizar el atributo *dataframe.values* para tener acceso al array 2D con toda la info del dataframe y utilizar el slicing como hemos visto en el módulo de Numpy.\n",
    "\n",
    "O bien, podríamos aprovechar la versatilidad de Pandas y usar los nombres de las columnas para decirle a Pandas de cuales columnas queremos formar un subset.\n",
    "\n",
    "Vamos a seguir trabajando con el set de datos *eficienciaEnergética.csv*\n",
    "\n",
    "Si quisieramos formar un subset de datos formado por las columnas *Relative_Compactness*, *Heating_Load* y *Cooling_Load* podríamos hacer lo siguiente,\n",
    "\n",
    "```python\n",
    "subset = datos[[\"Relative_Compactness\", \"Heating_Load\", \"Cooling_Load\"]]\n",
    "```\n",
    "\n",
    "Entonces, para obtener un subset estamos pasando una **lista** con los nombres de las columnas, del set de datos original, que queremos tomar para formar el subset.\n",
    "\n",
    "Veamos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8832b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = datos[[\"Relative_Compactness\", \"Heating_Load\", \"Cooling_Load\"]]\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e958c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notar que el orden en el cual pasemos la lista de nombres de columnas, tiene un efecto.\n",
    "test = datos[[\"Heating_Load\", \"Relative_Compactness\", \"Cooling_Load\"]]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75a020",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Ordenando los datos dentro del dataframe</span></center>\n",
    "\n",
    "Los DataFrame posee un método llamado [*DataFrane.sort_values()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) el cual nos permite ordenar los datos dentro del set especificando una o más columnas, de manera ascendente o descendente.\n",
    "\n",
    "Su implementación es,\n",
    "\n",
    "```python\n",
    "DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None\n",
    "```\n",
    "\n",
    "Nota: Si colocamos el atributo **inplace = True** estaremos indicando a Pandas que cambie el orden de los datos en el dataFrame original sin retornar nada.\n",
    "\n",
    "Según la documentación, el método *.sort_values()* retorna,\n",
    "\n",
    "    Returns\n",
    "    DataFrame or None. DataFrame with sorted values or None if inplace=True.\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos.sort_values(\"Relative_Compactness\", ascending = True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85841f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Podríamos ordenar por dos columnas\n",
    "datos.sort_values([\"Relative_Compactness\",\"Surface_Area\"], ascending = [True,False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2d4e2",
   "metadata": {},
   "source": [
    "Cuando hicimos, \n",
    "\n",
    "```python\n",
    "print(datos.sort_values([\"Relative_Compactness\",\"Surface_Area\"], ascending = [True,False]).head())\n",
    "```\n",
    "\n",
    "primero ordenamos los valores de manera ascendente según la columna *Relative_Compactness* y luego de manera descendente por la columna *Surface_Area*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a431e",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Creando subsets a partir de filtros</span></center>\n",
    "\n",
    "Con Pandas podemos crear subsets a partir de los valores dentro de una o más columnas del set de datos que cumplan con una o más condiciones. Esto es similar a lo que hemos visto en el módulo de Numpy, pero con la ventaja que podemos usar nombres de columnas para hacer el trabajo más ameno.\n",
    "\n",
    "Podríamos hacer,\n",
    "\n",
    "```python\n",
    "filtro1 = DataFrame[\"Columna de interes\"] < 50.\n",
    "filtro2 = DataFrame[\"Otra columna de interes\"] == \"unaPalabra\".\n",
    "\n",
    "subsetFiltrado = datosOriginales[filtro1]\n",
    "otroSubSet = datosOriginales[filtro2]\n",
    "subSet2Filtros = datosIRiginales[ filtro1 & filtro2 ]\n",
    "```\n",
    "\n",
    "<mark>**Importante**</mark>: Cuando creamos un filtro a partir de una o más condiciones, pandas nos devuelve un objeto del tipo *Series*. Los *pandas.series* contienen información **indexada**.\n",
    "\n",
    "Veamos algunos ejemplos con nuestro set *eficienciaEnergética.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c41d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generando un filtro\n",
    "\n",
    "## Queremos los datos de Relative_Compactness mayores a 0.9\n",
    "filtro1 = datos[\"Relative_Compactness\"]>0.9\n",
    "## Veamos qué tipo de datos nos da el filtrado\n",
    "print(type(filtro1))\n",
    "print()\n",
    "print(filtro1)\n",
    "\n",
    "\n",
    "##queremos los datos de Surface_Area menores a la media\n",
    "filtro2 = datos[\"Surface_Area\"] < datos[\"Surface_Area\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generamos nuestro subset\n",
    "subSetFiltrado = datos[filtro1 & filtro2]\n",
    "subSetFiltrado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Podemos hacer lo anterior en una sola línea\n",
    "subSet = datos[(datos[\"Relative_Compactness\"]>0.9) & (datos[\"Surface_Area\"] < datos[\"Surface_Area\"].mean())]\n",
    "\n",
    "## IMPORTANTE: Los filtros deben estar entre paréntesis\n",
    "subSet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283cea9",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Utilizando el método *.isin()* para filtrar por variables categóricas</span>\n",
    "\n",
    "En ocasiones podemos utilizar la función [*DataFrame.isin()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html) para filtrar todos los datos que le pasemos como parámetro. Es útil en general cuando tenemos variables categóricas.\n",
    "\n",
    "Supongamos que quisieramos formar un subset de datos con todas las casas que apuntan al norte y al sur dentro de *eficienciaEnergética.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtrNorteYsur = datos[\"Orientation\"].isin([2,3])\n",
    "subSetNyS = datos[filtrNorteYsur]\n",
    "subSetNyS.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d31314",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Creando nuevas columnas</span>\n",
    "\n",
    "En ocasiones es útil crear columnas que contengan información relevante a partir de realizar cálculos sobre los datos existentes en un dataframe.\n",
    "\n",
    "Con pandas es muy sencillo crear columnas nuevas.\n",
    "\n",
    "Supongamos que quisieramos crear una columna nueva con el total de carga de calor y carga de enfriamiento para cada hogar dentro del set de datos *eficienciaEnergética.csv*. Esto lo podemos hacer de la siguiente forma,\n",
    "\n",
    "```python\n",
    "datos[\"totalsLoad\"] = datos[\"Heating_Load\"] + datos[\"Cooling_Load\"]\n",
    "```\n",
    "\n",
    "Cuando hacemos *datos[\"totalsLoad\"]* le decimos a pandas que genere una nueva columna llamada *totalsLoad* y le asignamos, fila a fila, la suma de cada valor de *Heating_Load* y *Cooling_Load*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a14ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos[\"totalsLoad\"] = datos[\"Heating_Load\"] + datos[\"Cooling_Load\"]\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa0c2f",
   "metadata": {},
   "source": [
    "Podemos ver que ahora nuestro set de datos contiene una nueva columna llamada *totalsLoad*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f2d16",
   "metadata": {},
   "source": [
    "### <mark>**A practicar**</mark>\n",
    "\n",
    "Ejercicio 1 de *Ejercitación Teoría - Módulo Pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9efef",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Sacando valores estadísticos del set de datos</span>\n",
    "\n",
    "Los pandas.DataFrame traen varios métodos para obtener parámetros estadísticos a partir de sus columnas.\n",
    "\n",
    "Entre estas funciones tenemos:\n",
    "\n",
    "- mean()\n",
    "- median()\n",
    "- mode()\n",
    "- min()\n",
    "- max()\n",
    "- var()\n",
    "- std()\n",
    "- sum()\n",
    "- quantile()\n",
    "- cumsum()\n",
    "\n",
    "La forma de utilizarlas es muy sencilla, sólo pasamos la columna (o columnas) que queremos estudiar y aplicamos alguna de las funciones mencionadas.\n",
    "\n",
    "Supongamos que quisiéramos obtener algunos valores estadísticos de la carga de calor dentro de los datos de *eficienciaEnergética.csv*.\n",
    "\n",
    "Podríamos hacer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "media = datos[\"Heating_Load\"].mean()\n",
    "moda = datos[\"Heating_Load\"].mode()\n",
    "mediana = datos[\"Heating_Load\"].median()\n",
    "minimo = datos[\"Heating_Load\"].min()\n",
    "maximo = datos[\"Heating_Load\"].max()\n",
    "varianza = datos[\"Heating_Load\"].var()\n",
    "desvio = datos[\"Heating_Load\"].std()\n",
    "q30 = datos[\"Heating_Load\"].quantile(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c030c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La media es {media}\")\n",
    "print(f\"La moda es {moda}\")\n",
    "print(f\"La mediana es {mediana}\")\n",
    "print(f\"Mínimo es {minimo}. Máximo es {maximo}\")\n",
    "print(f\"La varianza es {varianza}. El desvío estándar es {desvio}\")\n",
    "print(f\"El cuantil 30 es {q30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eb907",
   "metadata": {},
   "source": [
    "La función *cumsum()* nos devuelve la suma acumulada y contiene la misma cantidad de datos que de filas tenga el set.\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4595fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsumHeating = datos[\"Heating_Load\"].cumsum()\n",
    "print(cumsumHeating.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cumsumHeating)\n",
    "plt.xlabel(\"Número de hogar\")\n",
    "plt.ylabel(\"Suma acumulada de carga de calor\")\n",
    "plt.title(\"Suma acumulada para columna Heating_Load\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135b5e7",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Función *agg()*</span>\n",
    "\n",
    "La función [*agg()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) nos permite implementar una función o varias, a lo largo de un axis del data frame.\n",
    "\n",
    "Su sintaxis es,\n",
    "\n",
    "```python\n",
    "DataFrame.agg(func=None, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "Veamos algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.agg(\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35398f9",
   "metadata": {},
   "source": [
    "Podemos ver que al hacer **datos.agg(\"min\")**, obtenemos los valores mínimos de todas las columnas.\n",
    "\n",
    "Podríamos crear nuestra propia función para hacer algo sobre una columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021fe0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(dato):\n",
    "    return dato/100\n",
    "    \n",
    "datos[[\"Heating_Load\", \"Cooling_Load\"]].agg(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculando el rango intercuartil de Heating_Load\n",
    "def interq(columna):\n",
    "    return columna.quantile(0.75) - columna.quantile(0.25)\n",
    "\n",
    "print(datos[\"Heating_Load\"].agg(interq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c5aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculando medias y medianas usando funciones de numpy\n",
    "import numpy as np\n",
    "\n",
    "print(datos[[\"Heating_Load\", \"Cooling_Load\"]].agg([np.mean, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64482f",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Sacando valores estadísticos del set de datos</span>\n",
    "\n",
    "En ocasiones necesitamos contabilizar ocurrencias que cumplan ciertas condiciones dentro del data frame.\n",
    "\n",
    "Pandas ofrece algunos métodos para realizar un conteo de cuántas veces cierto valor aparece en una columna del dataframe.\n",
    "\n",
    "En general, antes de realizar un conteo es necesario limpiar y/u obtener un subset de datos para realizar nuestro análisis o conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2f341",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Obteniendo valores únicos con *.drop_duplicates()*</span>\n",
    "\n",
    "Supongamos que tenemos un pequeño set de datos que muestra la visita de diferentes perros a una veterinaria.\n",
    "\n",
    "Cargamos el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1748e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitas = pd.read_csv(\"datasets/visitasVet.csv\")\n",
    "visitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f7aa1",
   "metadata": {},
   "source": [
    "Lo primero que debemos notar es que algunos perros han visitado la veterinaria más de una vez.\n",
    "\n",
    "Creemos un subset donde figuren solo una visita de cada perro a partir de su nombre.\n",
    "\n",
    "Esto lo podemos hacer con el método [*.drop_duplicates()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
    "\n",
    "```python\n",
    "DataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ed550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visitas.drop_duplicates(subset = \"nombre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8055d1b",
   "metadata": {},
   "source": [
    "Ahora tenemos un subset donde aparecen los perros sin repetir nombres. \n",
    "\n",
    "Pero **ojo**, <mark>¿donde está el perro Max de raza Chow Chow?</mark> Vemos que en el set original tenemos un perro llamado Max de raza Chow Chow pero que al descartar los duplicados, ya no aparece.\n",
    "\n",
    "¿Cómo podemos solucionar esto? Pasando una lista de subsets que contemeple los nombres y las razas de los perros a la función *.drop_duplicates()*.\n",
    "\n",
    "Veamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee042734",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicos = visitas.drop_duplicates(subset = [\"nombre\", \"raza\"])\n",
    "unicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4451292",
   "metadata": {},
   "source": [
    "Ahora sí tenemos a los dos perros llamados Max y podemos contabilizar realmente las razas en base a las visitas de perros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea79ad",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Contando con *.value_counts()*</span>\n",
    "\n",
    "Los dataframe tienen un método llamado [*.value_counts()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) que nos permite contar las ocurrencias dentro de una columna de datos. \n",
    "\n",
    "El método es\n",
    "\n",
    "```python\n",
    "DataFrame.value_counts(subset=None, normalize=False, sort=True, ascending=False, dropna=True)\n",
    "```\n",
    "\n",
    "Utilicemos el mismo para contabilizar las razas que tenemos dentro del subset unicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicos.value_counts(\"raza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaacabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicos.value_counts(subset = \"raza\", normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd19fb7",
   "metadata": {},
   "source": [
    "De la celda anterior podemos ver que el 28.5% de los perros son ChowChow o Labradores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0216c3",
   "metadata": {},
   "source": [
    "##### Alternativa\n",
    "\n",
    "Podemos hacer lo mismo que antes sin pasarle una columna al parámetro *subset*. Simplemente tomamos la columna que queremos contabilizar y aplicamos *.value_counts()*.\n",
    "\n",
    "Veamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d10329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unicos[\"raza\"].value_counts())\n",
    "print()\n",
    "print(unicos[\"raza\"].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63257d",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Aplicando operaciones por grupos usando *.groupby()*</span>\n",
    "\n",
    "La documentación oficial dice,\n",
    "\n",
    "> Group DataFrame using a mapper or by a Series of columns.\n",
    "\n",
    "> A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "Lo anterior nos dice que podemos usar el agrupamiento para aplicar operaciones a cada grupo.\n",
    "\n",
    "```python\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)\n",
    "```\n",
    "\n",
    "Es importante notar que esta función nos retorna un objeto especial llamado *pandas.core.groupby.generic.DataFrameGroupBy*, el cual es un objeto especial de Pandas.\n",
    "\n",
    "Veamos un ejemplo de como usarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f6235",
   "metadata": {},
   "source": [
    "##### ¿Cual raza es más pesada?\n",
    "\n",
    "Supongamos que quisieramos saber si alguna raza pesa más que la otra en promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b36ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agrupamos por raza\n",
    "meidasPorRaza = visitas.groupby(\"raza\").mean()\n",
    "meidasPorRaza ##es un dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b0767",
   "metadata": {},
   "source": [
    "Lo anterior es equivalente a,\n",
    "\n",
    "```python\n",
    "visitas[visitas[\"raza\"] == \"Beagle\"][\"peso_kg\"].mean()\n",
    "visitas[visitas[\"raza\"] == \"Chihuahua\"][\"peso_kg\"].mean()\n",
    "visitas[visitas[\"raza\"] == \"ChowChow\"][\"peso_kg\"].mean()\n",
    "visitas[visitas[\"raza\"] == \"Dalmata\"][\"peso_kg\"].mean()\n",
    "visitas[visitas[\"raza\"] == \"Labrador\"][\"peso_kg\"].mean()\n",
    "```\n",
    "\n",
    "Esto último puede ser complicado para grandes cantidades de datos y además puede ser fuente de errores o bugs en nuestro programa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003f942",
   "metadata": {},
   "source": [
    "Podemos formar un DataFrame con una mayor cantidad de datos referentes a los pesos por cada raza <mark>**agrupando datos con *.groupby()***</mark>, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "medidasPorRaza = visitas[[\"raza\",\"peso_kg\"]].groupby(\"raza\").agg([\"mean\",\"max\",\"min\"])\n",
    "medidasPorRaza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb13d0",
   "metadata": {},
   "source": [
    "Podríamos también agrupar por *raza* y *color* y obtener su media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agrupamos por raza\n",
    "meidasPorRazaYColor = visitas[[\"raza\",\"peso_kg\",\"color\"]].groupby([\"raza\", \"color\"]).agg([\"mean\",\"max\",\"min\"])\n",
    "meidasPorRazaYColor ##es un dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59574f60",
   "metadata": {},
   "source": [
    "##### Trabajando con los datos de eficiencia energética\n",
    "\n",
    "Supongamos que quisieramos comparar la carga total media necesaria para enfriar/calentar una casa en base a la orientación de las mismas.\n",
    "\n",
    "Podríamos usar lo visto hasta ahora sobre el set de datos de eficiencia energética, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60688ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposPorOrientation = datos.groupby(\"Orientation\")[[\"Heating_Load\",\"Cooling_Load\",\"totalsLoad\"]].mean()\n",
    "gruposPorOrientation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42719752",
   "metadata": {},
   "source": [
    "Vemos que no hay mucha diferencia entre las cargas de frío y calor en base a las orientaciones.\n",
    "\n",
    "¿Qué hay de las alturas de las casas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.groupby(\"Overall_Height\")[[\"Heating_Load\",\"Cooling_Load\",\"totalsLoad\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eeaaba",
   "metadata": {},
   "source": [
    "Evidentemente la altura de las casas tiene un impacto significatívo en lo que la carga de frío/calor para enfriar/calentar un hogar respecta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8c1af",
   "metadata": {},
   "source": [
    "¿Y respecto de la cantidad de ventanas en los hogares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.groupby([\"Glazing_Area\"])[[\"Heating_Load\",\"Cooling_Load\",\"totalsLoad\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c04c4",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Creando tablas dinámicas</span>\n",
    "\n",
    "Con las tablas pivote podemos formar tablas dinamicas. El método [*dataframe.pivot_table()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html) reconstruye el dataframe, para esto le decimos qué columna debe ocupar para formar los *valores* que formarán la tabla y la columna de la cual sus datos se convertirán en los nombres de las columnas de la tabla. Opcionalmente podemos pasarle a la función los índices, es decir, los nombres de las filas.\n",
    "\n",
    "Las tablas pivot son similares a las tables dinámicas de Excel o de Google Sheet.\n",
    "\n",
    "El método es el siguiente,\n",
    "\n",
    "```python\n",
    "DataFrame.pivot_table(values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True)\n",
    "```\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablaPivote = visitas.pivot_table(values = \"peso_kg\", index = \"color\", columns = \"raza\")\n",
    "tablaPivote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67458992",
   "metadata": {},
   "source": [
    "##### Missing values o Valores perdidos\n",
    "\n",
    "En la tabla anterior vemos algunos campos con valores *NaN*. Esto significa que no hay valores o se han perdido, para este caso particular es esperable, ya que nuestro set de datos no cuenta con Beagles de color blanco o perros de raza ChowChow de color blanco.\n",
    "\n",
    "Podríamos reemplazar estos valores *NaN* por algo mas conveniente utilizando el atributo *fill_value*, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45132f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablaPivote = visitas.pivot_table(values = \"peso_kg\", index = \"color\", columns = \"raza\", fill_value = 0)\n",
    "tablaPivote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ed9a1",
   "metadata": {},
   "source": [
    "Si hacemos el atributo *margins = True* obtendremos una fila y una columna con los valores medios de cada columna y cada fila, respectivamente, pero **sin contar los ceros**.\n",
    "\n",
    "Veamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablaPivote = visitas.pivot_table(values = \"peso_kg\", index = \"color\", columns = \"raza\", fill_value = 0, margins = True)\n",
    "tablaPivote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf211a",
   "metadata": {},
   "source": [
    "Utilizar *margins = TRue* nos otorga información valiosa desde el punto de vista estadístico ya que podemos, por ejemplo, saber el peso promedio para los Beagles que han visitado la veterinaria o bien el peso promedio para los perros de color marron, por citar un ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b5c83",
   "metadata": {},
   "source": [
    "##### Tabla pivote con datos de eficiencia energética\n",
    "\n",
    "Armemos una tabla pivote de los datos de eficiencia energética."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35577b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "otraPivote = datos.pivot_table(values = \"totalsLoad\", columns = \"Glazing_Area\", index = \"Relative_Compactness\",\n",
    "                               aggfunc=[\"mean\"], margins = True)\n",
    "otraPivote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c3e5c",
   "metadata": {},
   "source": [
    "En la tabla anterior podemos ver que los hogares con niveles de compactación por encima de 0.76 requieren una mayor cantidad de carga de frio/calor que los hogares de compactación por debajo de 0.76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "data = otraPivote.values\n",
    "labels = [glazing[1] for glazing in otraPivote.columns.tolist()]\n",
    "compact = otraPivote.index.tolist()\n",
    "   \n",
    "for i in range(data.shape[1]-1):\n",
    "    plt.scatter(compact[:len(compact)-1],data[:-1,i], label = f\"Glazing area {labels[i]}\")\n",
    "    \n",
    "plt.title(\"Carga de frío/calor medias para cada nivel de compactación\")\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel(\"Compactación\")\n",
    "plt.ylabel(\"Valores medios de frío/calor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24187c",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Obteniendo datos estadísticos por fila y columna</span>\n",
    "\n",
    "Si quisiéramos, podríamos aplicar algunas funciones a lo largo de filas o columnas de una tabla dinámica. Esto lo hacemos especificando la función a aplicar (mean(), sum(), min(), etc) y el axis sobre el cual queremos aplicarla, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## media sobre las filas\n",
    "tablaPivote.mean(axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874240ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## media sobre columnas\n",
    "tablaPivote.mean(axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c51b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "##máximos y mínimos\n",
    "otraPivote = datos.pivot_table(values = \"totalsLoad\", columns = \"Glazing_Area\", index = \"Relative_Compactness\",\n",
    "                               aggfunc=['max','min'], margins = True)\n",
    "otraPivote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd527931",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imprimiendo solo los valores máximos\n",
    "print(otraPivote[\"max\"])\n",
    "\n",
    "##obteniendo los máximos entre los máximos\n",
    "print(otraPivote[\"max\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d7bb9",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Creando índices en nuestros DataFrames</span>\n",
    "\n",
    "Hemos visto que en general cuando creamos un DataFrame a partir de leer un CSV obtenemos una tabla 2D con datos formados por filas y columnas. Por defecto, Pandas otorga un valor numérico, un **index**, a cada fila.\n",
    "\n",
    "Sin embargo, podríamos necesitar de crear tablas en donde los *index* no sean números sino que contengan algún tipo de información, de tal manera de poder obtener datos del DataFrame de manera diferente a cómo lo veníamos haciendo.\n",
    "\n",
    "Pandas nos ofrece algunos métodos para setear índices en nuestras tablas.\n",
    "\n",
    "Veamos el dataset de visitas de perros al veterinario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(visitas.index)\n",
    "visitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129d008",
   "metadata": {},
   "source": [
    "Podemos ver que la tabla de *visitas* contiene índices que van del 0 al 13, con pasos de a 1.\n",
    "\n",
    "Mediante el método [*DataFrame.set_index()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html) podemos generar índices a partir de los valores de una o más columnas.\n",
    "\n",
    "```python\n",
    "DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
    "```\n",
    "\n",
    "Veamos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seteando los índices según los nombres\n",
    "tablaPorNombre = visitas.set_index(\"nombre\")\n",
    "print(tablaPorNombre.index)\n",
    "tablaPorNombre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171ed87",
   "metadata": {},
   "source": [
    "Los índices ya no son numéricos sino que son los nombres de cada mascota.\n",
    "\n",
    "Ahora, con el meétodo [*.loc[]*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) podemos facilmente obtener información de uno o más perros utilizando estos nuevos índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e37cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imprimimos los datos de Branca\n",
    "print(tablaPorNombre.loc[\"Branca\"])\n",
    "\n",
    "## imprimimos los datos de Branca y de Max\n",
    "print(tablaPorNombre.loc[[\"Branca\", \"Max\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lo anterior es equivalente a\n",
    "visitas[visitas[\"nombre\"].isin([\"Branca\",\"Max\"])].sort_values(\"nombre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820d58c",
   "metadata": {},
   "source": [
    "##### Reiniciando índices\n",
    "\n",
    "Con el método *.reset_index()* logramos que pandas vuelva a formatear el dataframe para obtener su formato original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07789e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablaPorNombre.reset_index() ##vemos que la tabla ahora tiene la forma del dataframe original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83786eb",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Slicing de DataFrames</span>\n",
    "\n",
    "Podríamos hacer slicing en nuestros DataFrames utilizando los métodos [*.loc()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) e [*.iloc()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html). Debemos notar que estas funciones se buscan entre **índices y entre columnas**.\n",
    "\n",
    "Sigamos trabajando con los datos de mascotas visitando una veterinaria.\n",
    "\n",
    "Lo primero que debemos hacer es setear uno o más índices y luego **ordenar** el data fram usando *.sort_index()*.\n",
    "\n",
    "Veamos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e290d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Creamos un dataframe con los índices de raza y anidados los índices por color.\n",
    "## luego lo ordenamos.\n",
    "grupoRazaColor = visitas.set_index([\"raza\", \"color\"]).sort_index()\n",
    "grupoRazaColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTA: la función .sort_index() por defecto ordena los datos desde el índice externo (raza) hacia adentro (color)\n",
    "## En el caso anterior primero se ordena por raza y luego por color. Podríamos ordenar de otras maneras.\n",
    "## Ver documentación para mayor información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918f61a",
   "metadata": {},
   "source": [
    "#### ¿Cual es el shape de *grupoRazaColor*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupoRazaColor.shape ## ¿Qué paso con los índices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c166ee",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Realizando slicing con *.loc()*</span>\n",
    "\n",
    "Una vez que tenemos ordenados los datos dentro del dataframe podemos realizar slicing.\n",
    "\n",
    "En los siguientes ejemplos usaremos la función *.loc()*. Para indicar desde donde hasta donde queremos tomar datos, basta con poner **entre corchetes** los nombres de los índices, similar a lo que hemos hecho con numpy, pero en vez de utilizar números, usamos strings.\n",
    "\n",
    "```python\n",
    "DataFrame.loc[\"valor1\":\"valor2\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupoRazaColor.loc[\"Beagle\":\"ChowChow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53871ca3",
   "metadata": {},
   "source": [
    "**Importante**: Notar que los datos arrojados luego del Slicing **toman** a los perros correspondientes a *ChowChow*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a8fba",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Slicing con índices anidados</span>\n",
    "\n",
    "En los casos donde tegamos índices anidados debemos pasar una tupla con los valores que queremos obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36f9da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grupoRazaColor.loc[(\"Beagle\", \"negro_marron_blanco\"):(\"Dalmata\",\"blanco_negro\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450d995",
   "metadata": {},
   "source": [
    "**Nota:** Si intentáramos hacer slicing usando los índices internos pandas nos arrojaría un dataframe vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupoRazaColor.loc[\"negro\":\"marron\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc14c8b",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Slicing de columnas</span>\n",
    "\n",
    "También podríamos realizar slicing de columnas. Para esto separamos con una coma dentro de los corchetes para diferenciar las filas de las columnas (similar a lo que hacemos con slicing de ndarrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8dae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupoRazaColor.loc[(\"Beagle\", \"negro_marron_blanco\"):(\"Dalmata\",\"blanco_negro\") , \"nombre\":\"peso_kg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044b27c",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Slicing con *iloc[ ]*</span>\n",
    "\n",
    "Finalmente podríamos realizar slicing con iloc[], el cual nos permite seleccionar filas y columnas con valores enteros, exactamente igual a lo que hacemos con los ndarray de numpy.\n",
    "\n",
    "**Nota**: Al igual que con los slicing de ndarrays, si hacemos *.iloc[1:5,1:3]* estaremos indicando que queremos ir de la fila 1 hasta la 4 y de la columna 1 hasta la 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29048bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupoRazaColor.iloc[1:5, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f9b3c",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Graficando nuestros datos</span>\n",
    "\n",
    "Pandas posee métodos para graficar nuestros datos haciendo uso de la librería Matplotlib.\n",
    "\n",
    "A continuación veamos algunos de los métodos comúnmente utilizados.\n",
    "\n",
    "- *.hist()*\n",
    "- *.line()*\n",
    "- *.scatter()*\n",
    "- *.bar()*\n",
    "\n",
    "Utilizaremos los datos del dataset de visitas de perros.\n",
    "\n",
    "**Importante:** Para poder usar las funciones de graficación de Pandas debemos antes importar la librería matplotlib.\n",
    "\n",
    "```python\n",
    "import matplotlib as plt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cargamos el archivo\n",
    "visitas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c84ab",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Graficando histogramas</span>\n",
    "\n",
    "El método [*DataFrame.hist*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html) nos permite obtener rápidamente el histograma a partir de datos numéricos y/o categóricos.\n",
    "\n",
    "El método posee los siguientes parámetros,\n",
    "\n",
    "```python\n",
    "DataFrame.hist(column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, backend=None, legend=False, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f58622",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histograma de pesos\n",
    "## Para no repetir conteos vamos a sacar los valores repetidos\n",
    "\n",
    "visitas[\"peso_kg\"].hist(bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graficando pesos por sexo\n",
    "visitas[visitas[\"sexo\"] == \"F\"][\"peso_kg\"].hist(label = \"Fem\", grid = False)\n",
    "visitas[visitas[\"sexo\"] == \"M\"][\"peso_kg\"].hist(label = \"Mas\", alpha = 0.8, grid = False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc78904",
   "metadata": {},
   "source": [
    "### <span style='color:#381c88'>Gráficas de *dispersi+on* usando *.plot</span>\n",
    "\n",
    "Pandas posee el método [*DataFrame.plot*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) el cual integra la potencialidad del método *.plot()* de matplotlib, pero con la ventaja de que los datos a graficar ya están dentro del DataFrame.\n",
    "\n",
    "El método posee los siguientes parámetros,\n",
    "\n",
    "```python\n",
    "DataFrame.plot(*args, **kwargs)\n",
    "```\n",
    "\n",
    "Veamos algunos ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1239ef4",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Gráficas de *dispersión* usando *.plot</span>\n",
    "\n",
    "Si reemplazamos el parámetro *kind* con la palabra *scatter* podemos obtener una gráfica de dispersión, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graficando altura vs peso con gráfico de dispersión\n",
    "visitas.plot(x = \"altura_cm\", y = \"peso_kg\", kind = \"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034958e9",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Gráficas de *linea* usando *.plot</span>\n",
    "\n",
    "Si reemplazamos el parámetro *kind* con la palabra *line* podemos obtener una gráfica de línea, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34cc677",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitas[visitas[\"nombre\"] == \"Branca\"].plot(x = \"fecha\", y  =\"peso_kg\", rot = 45, title = \"Evolución peso de Branca\",\n",
    "                                           ylabel = \"Kg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00edc960",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Gráficas de *barra* usando *.plot</span>\n",
    "\n",
    "Si reemplazamos el parámetro *kind* con la palabra *bar* podemos obtener una gráfica de barras, veamos.\n",
    "\n",
    "*Nota:* Los gráficos de barra esperan datos **numéricos**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f5d9a",
   "metadata": {},
   "source": [
    "Vamos a graficar los pesos promedio por cada perro. Para esto vamos a agrupar por perro y luego calculamos los pesos promedios.\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesosPromedios = visitas.groupby(\"nombre\")[\"peso_kg\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680d1db",
   "metadata": {},
   "source": [
    "Una vez que tenemos los pesos promedio para cada perro pasamos a graficar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70066f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesosPromedios.plot(kind = \"bar\", title = \"Pesos promedio por cada mascota\", ylabel = \"Kg\", rot = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3962a8e",
   "metadata": {},
   "source": [
    "Pesos promedios para cada raza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitas.groupby(\"raza\")[\"peso_kg\"].mean().plot(kind = \"bar\", title = \"Pesos promedio por raza\", ylabel = \"Kg\", rot = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8600d52",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Datos faltantes</span>\n",
    "\n",
    "Es habitual encontrar lista de datos con valores perdidos. Cuando Pandas carga datos desde un archivo con datos faltantes, los reemplaza con la palabra <mark>**NaN**</mark>.\n",
    "\n",
    "Podemos detectarlos con el método [*.isna()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) el cual nos devuelve valores booleanos por cada dato dentro del dataframe y en caso de haber un *NaN* nos devuelve True.\n",
    "\n",
    "Carguemos ahora el set de datos *visitasVetNan* el cual representa la lista de visitas de diferentes perros a la veterinaria pero ahora con datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47745eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitasConNAN = pd.read_csv(\"datasets/visitasVetNan.csv\")\n",
    "visitasConNAN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4530b2",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos datos faltantes en los nbombres y también en los pesos. \n",
    "\n",
    "Podríamos ver si tenemos al menos **un** NaN en alguna de las columnas usando **.any()**. Veamos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ed73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## buscando NaN\n",
    "visitasConNAN.isna()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980619bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitasConNAN.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999da46",
   "metadata": {},
   "source": [
    "Vemos que tenemos al menos un valor *NaN* en las columnas *nombre*, *peso_kg* y *altura_cm*.\n",
    "\n",
    "Podemos contabilizar la cantidad de valores *NaN* usando *.sum()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitasConNAN.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dd94e",
   "metadata": {},
   "source": [
    "Con lo anterior vemos la cantidad de valores NaN por cada columna.\n",
    "\n",
    "Ahora bien, ¿Qué hacemos con estos datos perdidos?\n",
    "\n",
    "Usamos la función [*fillna()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) para reemplazar los NaN.\n",
    "\n",
    "Una posibilidad es usar *.dropna()* para elimnar todas las filas que tienen valores perdidos, pero esto puede ser perjudicial si tenemos muchos datos faltantes en nuestro set de datos.\n",
    "\n",
    "Otra posibilidad es llenar los datos con algún valor determinado. Existen muchas técnicas, algunas muy complejas y otras sencillas.\n",
    "\n",
    "Por ejemplo, podríamos llenar los perros con nombre desconocidos con la palabra \"NN\". Aquellos valores faltantes en las columnas de *peso_kg* y *altura_cm* podemos completarlos con los valores medios de cada columna (una técnica mas compleja podría ser sacar las medias por cada raza y en base a eso completar los valores faltantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## completando columna nombre\n",
    "visitasConNAN[\"nombre\"] = visitasConNAN[\"nombre\"].fillna(\"NN\")\n",
    "visitasConNAN[\"peso_kg\"] = visitasConNAN[\"peso_kg\"].fillna(visitasConNAN[\"peso_kg\"].mean())\n",
    "visitasConNAN[\"altura_cm\"] = visitasConNAN[\"altura_cm\"].fillna(visitasConNAN[\"altura_cm\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## revisando datos\n",
    "visitasConNAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255124c4",
   "metadata": {},
   "source": [
    "## <span style='color:#f06553'>Creando DataFrames a partir de diccionarios</span>\n",
    "\n",
    "Es evidente que los DataFrame pueden ser vistos como diccionarios, donde cada columna puede ser visto como un key. Con esta idea es que podemos crear dataframe o agregar datos a uno ya existente.\n",
    "\n",
    "Como ya sabemos, la sintáxis general para crear un diccionario es la siguiente,\n",
    "\n",
    "```python\n",
    "dic = {\n",
    "    \"key1\":valor1,\n",
    "    \"key2\":valor2,\n",
    "    \"keye\":valor3\n",
    "}\n",
    "```\n",
    "\n",
    "Luego con el método DataFrame de Pandas creamos el dataframe a partir de pasar una lista con el (o los diccionarios)\n",
    "\n",
    "```python\n",
    "dataframe = pd.DataFrame(data = [dic])\n",
    "```\n",
    "\n",
    "Si quisieramos seguir con el formato del set de datos de visitas de perros a la veterinaria podríamos hacer:\n",
    "\n",
    "```python\n",
    "dic = {\n",
    "    \"fecha\":\"1/17/2018\",\n",
    "    \"nombre\":\"Perro de John\",\n",
    "    \"raza\":\"Beagle\",\n",
    "    \"peso_kg\":1.5,\n",
    "    \"altura_cm\":10.2,\n",
    "    \"color\":\"negro_marron_blanco\",\n",
    "    \"sexo\":\"F\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67210ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1 = {\n",
    "    \"fecha\":\"1/17/2018\",\n",
    "    \"nombre\":\"Perro de John\",\n",
    "    \"raza\":\"Beagle\",\n",
    "    \"peso_kg\":1.5,\n",
    "    \"altura_cm\":10.2,\n",
    "    \"color\":\"negro_marron_blanco\",\n",
    "    \"sexo\":\"F\"\n",
    "}\n",
    "\n",
    "dic2 = {\n",
    "    \"fecha\":\"1/25/2019\",\n",
    "    \"nombre\":\"Morfeo\",\n",
    "    \"raza\":\"Labrador\",\n",
    "    \"peso_kg\":42.5,\n",
    "    \"altura_cm\":45.5,\n",
    "    \"color\":\"marron\",\n",
    "    \"sexo\":\"M\"\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data = [dic1,dic2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53587973",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>DataFrame a partir de diccionario de listas</span></center>\n",
    "\n",
    "Una alternativa a la creación del DataFrame de las celdas anteriores es crear un diccionario que contenga las *key* y por cada una de esta, una lista con los datos del DataFrame, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicList = {\n",
    "    \"fecha\":[\"1/17/2018\", \"1/25/2019\"],\n",
    "    \"nombre\":[\"Perro de John\", \"Morfeo\"],\n",
    "    \"raza\":[\"Beagle\", \"Labrador\"],\n",
    "    \"peso_kg\":[1.5, 42.5],\n",
    "    \"altura_cm\":[10.2, 45.5],\n",
    "    \"color\":[\"negro_marron_blanco\", \"marron\"],\n",
    "    \"sexo\":[\"F\", \"M\"]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data = dicList)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eebca6",
   "metadata": {},
   "source": [
    "#### <span style='color:#55aa74'>Crear un DataFrame con índices a partir de un Diccionario</span></center>\n",
    "\n",
    "Podríamos crear un dataframe con índices en las filas. Para esto anidamos diccionarios, donde el diccionario más externo es el que indicará el nombre del índice.\n",
    "\n",
    "Veamos el siguiente ejemplo obtenido de [acá](https://realpython.com/pandas-read-write-files/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe188a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Diccionario\n",
    "dic = {\n",
    "    'CHN': {'COUNTRY': 'China', 'POP': 1_398.72, 'AREA': 9_596.96,\n",
    "            'GDP': 12_234.78, 'CONT': 'Asia'},\n",
    "    'IND': {'COUNTRY': 'India', 'POP': 1_351.16, 'AREA': 3_287.26,\n",
    "            'GDP': 2_575.67, 'CONT': 'Asia', 'IND_DAY': '1947-08-15'},\n",
    "    'USA': {'COUNTRY': 'US', 'POP': 329.74, 'AREA': 9_833.52,\n",
    "            'GDP': 19_485.39, 'CONT': 'N.America',\n",
    "            'IND_DAY': '1776-07-04'},\n",
    "    'IDN': {'COUNTRY': 'Indonesia', 'POP': 268.07, 'AREA': 1_910.93,\n",
    "            'GDP': 1_015.54, 'CONT': 'Asia', 'IND_DAY': '1945-08-17'},\n",
    "    'BRA': {'COUNTRY': 'Brazil', 'POP': 210.32, 'AREA': 8_515.77,\n",
    "            'GDP': 2_055.51, 'CONT': 'S.America', 'IND_DAY': '1822-09-07'},\n",
    "    'PAK': {'COUNTRY': 'Pakistan', 'POP': 205.71, 'AREA': 881.91,\n",
    "            'GDP': 302.14, 'CONT': 'Asia', 'IND_DAY': '1947-08-14'},\n",
    "    'NGA': {'COUNTRY': 'Nigeria', 'POP': 200.96, 'AREA': 923.77,\n",
    "            'GDP': 375.77, 'CONT': 'Africa', 'IND_DAY': '1960-10-01'},\n",
    "    'BGD': {'COUNTRY': 'Bangladesh', 'POP': 167.09, 'AREA': 147.57,\n",
    "            'GDP': 245.63, 'CONT': 'Asia', 'IND_DAY': '1971-03-26'},\n",
    "    'RUS': {'COUNTRY': 'Russia', 'POP': 146.79, 'AREA': 17_098.25,\n",
    "            'GDP': 1_530.75, 'IND_DAY': '1992-06-12'},\n",
    "    'MEX': {'COUNTRY': 'Mexico', 'POP': 126.58, 'AREA': 1_964.38,\n",
    "            'GDP': 1_158.23, 'CONT': 'N.America', 'IND_DAY': '1810-09-16'},\n",
    "    'JPN': {'COUNTRY': 'Japan', 'POP': 126.22, 'AREA': 377.97,\n",
    "            'GDP': 4_872.42, 'CONT': 'Asia'},\n",
    "    'DEU': {'COUNTRY': 'Germany', 'POP': 83.02, 'AREA': 357.11,\n",
    "            'GDP': 3_693.20, 'CONT': 'Europe'},\n",
    "    'FRA': {'COUNTRY': 'France', 'POP': 67.02, 'AREA': 640.68,\n",
    "            'GDP': 2_582.49, 'CONT': 'Europe', 'IND_DAY': '1789-07-14'},\n",
    "    'GBR': {'COUNTRY': 'UK', 'POP': 66.44, 'AREA': 242.50,\n",
    "            'GDP': 2_631.23, 'CONT': 'Europe'},\n",
    "    'ITA': {'COUNTRY': 'Italy', 'POP': 60.36, 'AREA': 301.34,\n",
    "            'GDP': 1_943.84, 'CONT': 'Europe'},\n",
    "    'ARG': {'COUNTRY': 'Argentina', 'POP': 44.94, 'AREA': 2_780.40,\n",
    "            'GDP': 637.49, 'CONT': 'S.America', 'IND_DAY': '1816-07-09'},\n",
    "    'DZA': {'COUNTRY': 'Algeria', 'POP': 43.38, 'AREA': 2_381.74,\n",
    "            'GDP': 167.56, 'CONT': 'Africa', 'IND_DAY': '1962-07-05'},\n",
    "    'CAN': {'COUNTRY': 'Canada', 'POP': 37.59, 'AREA': 9_984.67,\n",
    "            'GDP': 1_647.12, 'CONT': 'N.America', 'IND_DAY': '1867-07-01'},\n",
    "    'AUS': {'COUNTRY': 'Australia', 'POP': 25.47, 'AREA': 7_692.02,\n",
    "            'GDP': 1_408.68, 'CONT': 'Oceania'},\n",
    "    'KAZ': {'COUNTRY': 'Kazakhstan', 'POP': 18.53, 'AREA': 2_724.90,\n",
    "            'GDP': 159.41, 'CONT': 'Asia', 'IND_DAY': '1991-12-16'}\n",
    "}\n",
    "\n",
    "columns = ('COUNTRY', 'POP', 'AREA', 'GDP', 'CONT', 'IND_DAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## obteniendo un DataFrame\n",
    "otroDF = pd.DataFrame(data = dic).T\n",
    "otroDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9521d",
   "metadata": {},
   "source": [
    "Podríamos acceder a los datos de alguno de los países usando los índices y la función *.loc[ ]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(otroDF.loc[\"IND\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d2cff",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid #55E227\"> </hr>\n",
    "\n",
    "### FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pda]",
   "language": "python",
   "name": "conda-env-pda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
